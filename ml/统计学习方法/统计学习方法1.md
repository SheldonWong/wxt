
2018.08.03

1.1 统计学习
机器学习定义：
- Mitchell：E，P，T，对于一个Task，如果可以借助经验E，提高Task的性能P。
- 从统计角度：统计学分为描述统计学和推理统计学，
李航认为，统计学习方法是由模型、策略和算法构成的，其中
模型就是所要学习的条件概率分布或决策函数，
策略就是依照什么样的准则学习或选择最优的模型，
算法就是用什么样的计算方法求解最优模型。
这时，统计学习问题归结为最优化问题，统计学习的算法成为求解最优化问题的的算法。如果最优化问题有显示的解析解，这个最优化问题就比较简单，但通常解析解不存在，这就需要用数值计算的方法求解，如何保证找到全局最优解，并使求解的过程非常高效，就成为一个重要问题。

- 从给定的、有限的、用于学习的训练数据集出发，假设数据是独立同分布产生的；并且假设要学习的模型属于某个函数的集合，称为假设空间；应用某个评价准则，从假设空间中宣州区一个最优的模型，使它对一直训练数据及未知测试数据在给定的评价准则下有最优的预测。最优模型的选择由算法实现。这样，统计学习方法包括模型的假设空间，模型选择的准则以及模型学习的算法。即模型、策略、算法。

1.2 监督学习
- 基本概念
	- 输入空间
	- 特征空间
	- 输出空间
	- 联合概率分布
	- 假设空间：学习的模型可以是条件概率分布P（Y|X）或决策函数Y=f(X)
- 问题的形式化 

1.3 统计学习三要素
- 模型
- 策略
	- 按照什么样的准则选择最优的模型
	- 损失函数度量模型一次预测的好坏，风险函数度量平均意义下模型预测的好坏
	- 预测值f(X)和真实值Y可能一致也可能不一致，用一个损失函数或代价函数来度量预测错误的程度。记做L(Y,f(X))
	- 常用的损失函数包括0-1损失函数，平方损失，绝对损失，对数损失
	- 学习的目标是选择期望风险最小的模型，由于联合分布P（X，Y）未知，所以期望风险不能直接计算，如果知道联合分布P(X,Y)，可以从联合分布直接求出条件概率分布P(Y|X)，也就不需要学习了，正因为不知道联合概率分布，所以才需要学习。这样一来，一方面根据期望风险最小学习模型需要用到联合分布，另一方面联合分布又是未知的，所以监督学习就称为一个病态问题。
	- 期望风险是模型关于联合分布的期望损失，经验风险是模型关于训练样本的平均损失。根据大数定律，当样本量区域无穷时，经验风险趋于期望风险。但是由于现实中训练样本数目有限，甚至很小，所以要用经验风险估计期望风险常常并不理想，要对经验风险进行一定的矫正，这就关系到减速学习的基本策略：经验风险最小化与结构风险最小化。
	- 经验风险：样本，损失函数，极大似然就是经验风险最小化的一个例子。
	- 结构风险：参数，通过正则化项来惩罚参数，贝叶斯估计中的最大后验概率估计就是结构风险最小化的例子
- 算法

1.4 模型评估与模型选择
- 训练误差与测试误差
	- 通常将学习方法对未知数据的预测能力称为泛化能力。
- 过拟合与模型选择
	- 过拟合：如果一味追求提高对训练数据的预测能力，所选模型的复杂度往往会比真模型更高，这种现象称为过拟合
	- 过拟合是指学习时所选的模型包含的参数过多，以至于出现这一模型对已知数据预测的很好，但对未知数据预测的很差的现象。可以说模型选择旨在避免过拟合并提高模型的预测能力。
	- 模型选择就是选择在未知数据集上预测性能较好的模型
	- 两种常用的模型选择方法：正则化与交叉验证

1.5 正则化与交叉验证
- 正则化
	- 正则化是结构风险最小化策略的实现，实在经验风险上加一个正则化项或罚项。正则化项一般是模型复杂度的单调递增函数，模型复杂度越大，正则化值就越大。
	- 正则化项复合奥卡姆剃刀原则，在所有可能选择的模型中，能够很好的解释数据并且十分简单才是最好的模型。
- 交叉验证
	- 如果给定的数据充足，进行模型选择的一种简单方法是随机的将数据集切分成三个部分，分别是训练集、验证集和测试集。训练集用来训练模型，验证集用于模型的选择，二测试集用于最终对学习方法的评估。在学习到的所有模型中，选择对验证集有最小预测误差的模型。
	- 实际中数据是不充足的，为了选择好的模型，可以采用交叉验证方法。交叉验证的基本想法是重复使用数据。把给定的数据进行切分，将切分的数据集组合为训练集与测试集，在此基础上反复进行训练、测试、模型选择
	- 简单交叉验证:随机将数据分成测试集和训练集，用训练集在不同条件下训练，得到各种模型，在测试集上评价误差，选择测试误差最小的模型。
	- S折交叉验证：随机将数据切分成S个子集，利用S-1个训练数据，剩余的一个子集测试模型；将这一过程可能的S种选择重复进行；最后选出S次评测中，平均测试误差最小的。
	- 留一交叉验证：S折交叉验证的特殊情形，S=N，N是样本集的数量。

1.6 泛化能力
- 模型对未知数据的预测能力，显示中采用最多的办法是通过测试误差类似评价学习方法的泛化能力，但这种评价是依赖于测试集的，测试集往往是有限的，很可能得到的结果是不可靠的，统计学习理论试图从理论上对学习方法的泛化能力进行分析。

1.7 生成模型与判别模型
- 生成模型：生成模型由数据学习联合分布，再求出条件概率分布，作为预测的模型P（Y|X），例如朴素贝叶斯/HMM，生成模型可以还原出联合分布，收敛更快，可以处理隐变量问题。
- 判别模型：判别模型直接学习决策函数f(X)或者条件个概率分布P(Y|X),例如k近临/感知机/决策书/LR/最大熵/SVM/Boosting方法/条件随机场等，判别方法往往学习的准确率更高。

1.8 分类问题
- 混淆矩阵：
- 通常以关注的类为正类，其他类为负类
- 准确率：正确分类的样本数/测试集总样本数
- 精确率：预测为正类正确的/预测集中为正类的样本数
- 召回率：预测为正类正确的/测试集中的正类样本数
- F1-Score：精确率和召回率的调和均值
- AUC与ROC：

1.9 标注问题
- 标注常用的统计学习方法有：HMM，条件随机场。
- 词性标注是一个典型的标注问题。 

1.10 回归问题
- 回归问题的学习等价于函数的拟合：选择一条函数曲线使其很好地拟合已知数据并很好的预测未知数据
- 回归问题按照输入变量的个数，分为一元回归和多元回归ancha输入变量和输出变量之间关系的类型即模型的类型，分为线性回归和非线性回归

- 遗留问题：
- AUC与ROC
- 泛化上届

