## 感知机
2.1 感知机模型
- 感知机模型：由输入空间到输出空间的映射函数f(x)=sign(wx+b)，其中w叫做权值向量，b叫做偏置，wx表示w和x的内积，sign是符号函数。
- 

2.2 感知机学习策略
- 如果存在某个超平面S wx+b=0,能够将数据集的正例和负例点完全正确的划分到超哦平面的两侧，即对所有的正例y_i = +1,有wx+b>0，对所有的负例y_i=-1，有wx+b<0称数据集T为线性可分数据集。
- 损失函数的的另一个选择是误分类点到超平面S的总距离
- 误分类点x_i到超平面S的距离是 \frac{-1}{||w||} y_i(wx_i+b),这样假设超平面S的误分类点集合为M，那么所有误分类点到超平面S的总距离为-\frac{1}{||w||}\sum_{x_i \in M}{y_i(w \bullet x_i+b)}，不考虑\frac{1}{||w||}，就得到感知机学习的损失函数
- 感知机学习的损失函数定义为L(w,b)=-\sum_{x_i \in M}{y_i(w \bullet x_i+b)}

2.3 感知机学习算法
2.3.1 感知机学习算法的原始形式
- 初始化w_0,b_0
- 在训练集中选取数据（x_i,y_i）
- 如果y_i(wx_i+b)<=0,更新w,b:
	- w = w+\alpha y_i x_i
	- b = b=b+\alpha y_i
- 跳转至(2)，直到训练集没有误分类点。
2.3.2 算法的收敛性

2.3.3 感知机学习算法的对偶形式
- 对偶形式的基本想法是，将w和b表示为实例x_i和y_i的线性组合的形式，通过求解其系数而求得w和b
- 输出：\alpha,b;感知机模型f(x)=sign(\sum_{j=1}^{N}{})
### 存在的问题
- 习题1,3
- 算法的收敛性
