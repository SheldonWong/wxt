{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.13 (default, Dec 28 2018, 23:19:56) \n",
      "[GCC 4.8.4]\n",
      "sys.version_info(major=2, minor=7, micro=13, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python  \n",
    "import sys  \n",
    "print(sys.version) \n",
    "print(sys.version_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MovieInfo id(1), title(Toy Story ), categories([u'Animation', u\"Children's\", u'Comedy'])>\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "movie_info = paddle.dataset.movielens.movie_info()\n",
    "print movie_info.values()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<UserInfo id(1), gender(F), age(1), job(10)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "user_info = paddle.dataset.movielens.user_info()\n",
    "print user_info.values()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User <UserInfo id(1), gender(F), age(1), job(10)> rates Movie <MovieInfo id(1193), title(One Flew Over the Cuckoo's Nest ), categories([u'Drama'])> with Score [5.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_set_creator = paddle.dataset.movielens.train()\n",
    "train_sample = next(train_set_creator())\n",
    "uid = train_sample[0]\n",
    "mov_id = train_sample[len(user_info[uid].value())]\n",
    "print \"User %s rates Movie %s with Score %s\"%(user_info[uid], movie_info[mov_id], train_sample[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<UserInfo id(1), gender(F), age(1), job(10)>, <MovieInfo id(1193), title(One Flew Over the Cuckoo's Nest ), categories([u'Drama'])>, [5.0])\n"
     ]
    }
   ],
   "source": [
    "print(user_info[uid], movie_info[mov_id], train_sample[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "import numpy as np\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "import paddle.fluid.layers as layers\n",
    "import paddle.fluid.nets as nets\n",
    "\n",
    "IS_SPARSE = True\n",
    "USE_GPU = False\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_usr_combined_features():\n",
    "\n",
    "    USR_DICT_SIZE = paddle.dataset.movielens.max_user_id() + 1\n",
    "\n",
    "    uid = layers.data(name='user_id', shape=[1], dtype='int64')\n",
    "\n",
    "    usr_emb = layers.embedding(\n",
    "        input=uid,\n",
    "        dtype='float32',\n",
    "        size=[USR_DICT_SIZE, 32],\n",
    "        param_attr='user_table',\n",
    "        is_sparse=IS_SPARSE)\n",
    "\n",
    "    usr_fc = layers.fc(input=usr_emb, size=32)\n",
    "\n",
    "    USR_GENDER_DICT_SIZE = 2\n",
    "\n",
    "    usr_gender_id = layers.data(name='gender_id', shape=[1], dtype='int64')\n",
    "\n",
    "    usr_gender_emb = layers.embedding(\n",
    "        input=usr_gender_id,\n",
    "        size=[USR_GENDER_DICT_SIZE, 16],\n",
    "        param_attr='gender_table',\n",
    "        is_sparse=IS_SPARSE)\n",
    "\n",
    "    usr_gender_fc = layers.fc(input=usr_gender_emb, size=16)\n",
    "\n",
    "    USR_AGE_DICT_SIZE = len(paddle.dataset.movielens.age_table)\n",
    "    usr_age_id = layers.data(name='age_id', shape=[1], dtype=\"int64\")\n",
    "\n",
    "    usr_age_emb = layers.embedding(\n",
    "        input=usr_age_id,\n",
    "        size=[USR_AGE_DICT_SIZE, 16],\n",
    "        is_sparse=IS_SPARSE,\n",
    "        param_attr='age_table')\n",
    "\n",
    "    usr_age_fc = layers.fc(input=usr_age_emb, size=16)\n",
    "\n",
    "    USR_JOB_DICT_SIZE = paddle.dataset.movielens.max_job_id() + 1\n",
    "    usr_job_id = layers.data(name='job_id', shape=[1], dtype=\"int64\")\n",
    "\n",
    "    usr_job_emb = layers.embedding(\n",
    "        input=usr_job_id,\n",
    "        size=[USR_JOB_DICT_SIZE, 16],\n",
    "        param_attr='job_table',\n",
    "        is_sparse=IS_SPARSE)\n",
    "\n",
    "    usr_job_fc = layers.fc(input=usr_job_emb, size=16)\n",
    "\n",
    "    concat_embed = layers.concat(\n",
    "        input=[usr_fc, usr_gender_fc, usr_age_fc, usr_job_fc], axis=1)\n",
    "\n",
    "    usr_combined_features = layers.fc(input=concat_embed, size=200, act=\"tanh\")\n",
    "\n",
    "    return usr_combined_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mov_combined_features():\n",
    "\n",
    "    MOV_DICT_SIZE = paddle.dataset.movielens.max_movie_id() + 1\n",
    "\n",
    "    mov_id = layers.data(name='movie_id', shape=[1], dtype='int64')\n",
    "\n",
    "    mov_emb = layers.embedding(\n",
    "        input=mov_id,\n",
    "        dtype='float32',\n",
    "        size=[MOV_DICT_SIZE, 32],\n",
    "        param_attr='movie_table',\n",
    "        is_sparse=IS_SPARSE)\n",
    "\n",
    "    mov_fc = layers.fc(input=mov_emb, size=32)\n",
    "\n",
    "    CATEGORY_DICT_SIZE = len(paddle.dataset.movielens.movie_categories())\n",
    "\n",
    "    category_id = layers.data(\n",
    "        name='category_id', shape=[1], dtype='int64', lod_level=1)\n",
    "\n",
    "    mov_categories_emb = layers.embedding(\n",
    "        input=category_id, size=[CATEGORY_DICT_SIZE, 32], is_sparse=IS_SPARSE)\n",
    "\n",
    "    mov_categories_hidden = layers.sequence_pool(\n",
    "        input=mov_categories_emb, pool_type=\"sum\")\n",
    "\n",
    "    MOV_TITLE_DICT_SIZE = len(paddle.dataset.movielens.get_movie_title_dict())\n",
    "\n",
    "    mov_title_id = layers.data(\n",
    "        name='movie_title', shape=[1], dtype='int64', lod_level=1)\n",
    "\n",
    "    mov_title_emb = layers.embedding(\n",
    "        input=mov_title_id, size=[MOV_TITLE_DICT_SIZE, 32], is_sparse=IS_SPARSE)\n",
    "\n",
    "    mov_title_conv = nets.sequence_conv_pool(\n",
    "        input=mov_title_emb,\n",
    "        num_filters=32,\n",
    "        filter_size=3,\n",
    "        act=\"tanh\",\n",
    "        pool_type=\"sum\")\n",
    "\n",
    "    concat_embed = layers.concat(\n",
    "        input=[mov_fc, mov_categories_hidden, mov_title_conv], axis=1)\n",
    "\n",
    "    mov_combined_features = layers.fc(input=concat_embed, size=200, act=\"tanh\")\n",
    "\n",
    "    return mov_combined_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_program():\n",
    "    usr_combined_features = get_usr_combined_features()\n",
    "    mov_combined_features = get_mov_combined_features()\n",
    "\n",
    "    inference = layers.cos_sim(X=usr_combined_features, Y=mov_combined_features)\n",
    "    scale_infer = layers.scale(x=inference, scale=5.0)\n",
    "\n",
    "    return scale_infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_program():\n",
    "\n",
    "    scale_infer = inference_program()\n",
    "\n",
    "    label = layers.data(name='score', shape=[1], dtype='float32')\n",
    "    square_cost = layers.square_error_cost(input=scale_infer, label=label)\n",
    "    avg_cost = layers.mean(square_cost)\n",
    "\n",
    "    return [avg_cost, scale_infer]\n",
    "\n",
    "\n",
    "def optimizer_func():\n",
    "    return fluid.optimizer.SGD(learning_rate=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = False\n",
    "place = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reader = paddle.batch(\n",
    "    paddle.reader.shuffle(\n",
    "        paddle.dataset.movielens.train(), buf_size=8192),\n",
    "    batch_size=BATCH_SIZE)\n",
    "\n",
    "test_reader = paddle.batch(\n",
    "    paddle.dataset.movielens.test(), batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__builtins__', '__doc__', '__file__', '__name__', '__package__', 'commit', 'full_version', 'istaged', 'major', 'minor', 'mkl', 'patch', 'rc', 'show', 'with_mkl']\n",
      "('full_version:', '1.2.0')\n",
      "('major:', '1')\n",
      "('minor:', '2')\n",
      "('patch:', '0')\n",
      "('rc:', '0')\n",
      "None\n",
      "['__class__', '__delattr__', '__dict__', '__doc__', '__format__', '__getattribute__', '__hash__', '__init__', '__module__', '__new__', '__prepare_parameter__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__use_remote_sparse_updater__', '__weakref__', 'get_topology_proto', 'save_parameter_to_tar', 'test', 'train']\n"
     ]
    }
   ],
   "source": [
    "print(dir(paddle.version))\n",
    "print(paddle.version.show())\n",
    "print(dir(paddle.v2.trainer.SGD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_order = [\n",
    "    'user_id', 'gender_id', 'age_id', 'job_id', 'movie_id', 'category_id',\n",
    "    'movie_title', 'score'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main_program = fluid.default_main_program()\n",
    "star_program = fluid.default_startup_program()\n",
    "[avg_cost, scale_infer] = train_program()\n",
    "\n",
    "test_program = main_program.clone(for_test=True)\n",
    "sgd_optimizer = optimizer_func()\n",
    "sgd_optimizer.minimize(avg_cost)\n",
    "exe = fluid.Executor(place)\n",
    "\n",
    "def train_test(program, reader):\n",
    "    count = 0\n",
    "    feed_var_list = [\n",
    "        program.global_block().var(var_name) for var_name in feed_order\n",
    "    ]\n",
    "    feeder_test = fluid.DataFeeder(\n",
    "    feed_list=feed_var_list, place=place)\n",
    "    test_exe = fluid.Executor(place)\n",
    "    accumulated = len([avg_cost, scale_infer]) * [0]\n",
    "    for test_data in reader():\n",
    "        avg_cost_np = test_exe.run(program=program,\n",
    "                                               feed=feeder_test.feed(test_data),\n",
    "                                               fetch_list=[avg_cost, scale_infer])\n",
    "        accumulated = [x[0] + x[1][0] for x in zip(accumulated, avg_cost_np)]\n",
    "        count += 1\n",
    "    return [x / count for x in accumulated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dirname = \"recommender_system.inference.model\"\n",
    "\n",
    "from paddle.utils.plot import Ploter\n",
    "test_prompt = \"Test cost\"\n",
    "plot_cost = Ploter(test_prompt)\n",
    "\n",
    "def train_loop():\n",
    "    feed_list = [\n",
    "        main_program.global_block().var(var_name) for var_name in feed_order\n",
    "    ]\n",
    "    feeder = fluid.DataFeeder(feed_list, place)\n",
    "    exe.run(star_program)\n",
    "\n",
    "    for pass_id in range(PASS_NUM):\n",
    "        for batch_id, data in enumerate(train_reader()):\n",
    "            # train a mini-batch\n",
    "            outs = exe.run(program=main_program,\n",
    "                               feed=feeder.feed(data),\n",
    "                               fetch_list=[avg_cost])\n",
    "            out = np.array(outs[0])\n",
    "\n",
    "            avg_cost_set = train_test(test_program, test_reader)\n",
    "\n",
    "            # get test avg_cost\n",
    "            test_avg_cost = np.array(avg_cost_set).mean()\n",
    "            plot_cost.append(test_prompt, batch_id, outs[0])\n",
    "            plot_cost.plot()\n",
    "            print(\"avg_cost: %s\" % test_avg_cost)\n",
    "\n",
    "            if batch_id == 20:\n",
    "                if params_dirname is not None:\n",
    "                    fluid.io.save_inference_model(params_dirname, [\n",
    "                                \"user_id\", \"gender_id\", \"age_id\", \"job_id\",\n",
    "                                \"movie_id\", \"category_id\", \"movie_title\"\n",
    "                        ], [scale_infer], exe)\n",
    "                return\n",
    "            else:\n",
    "                print('BatchID {0}, Test Loss {1:0.2}'.format(pass_id + 1,\n",
    "                                                                  float(test_avg_cost)))\n",
    "\n",
    "            if math.isnan(float(out[0])):\n",
    "                sys.exit(\"got NaN loss, training failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'PASS_NUM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-6590b82f66d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-f2c81ad9d676>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mexe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstar_program\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mpass_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPASS_NUM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;31m# train a mini-batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'PASS_NUM' is not defined"
     ]
    }
   ],
   "source": [
    "train_loop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<paddle.fluid.core.LoDTensor object at 0x7fe0d591c7d8>, <paddle.fluid.core.LoDTensor object at 0x7fe0d832b1f0>, <paddle.fluid.core.LoDTensor object at 0x7fe0d591cb90>, <paddle.fluid.core.LoDTensor object at 0x7fe0d591c810>, <paddle.fluid.core.LoDTensor object at 0x7fe0d591cca8>, <paddle.fluid.core.LoDTensor object at 0x7fe0d591ca08>, <paddle.fluid.core.LoDTensor object at 0x7fe0d591cc00>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "infer_movie_id = 783\n",
    "infer_movie_name = paddle.dataset.movielens.movie_info()[infer_movie_id].title\n",
    "user_id = fluid.create_lod_tensor([[1]], [[1]], place)\n",
    "gender_id = fluid.create_lod_tensor([[1]], [[1]], place)\n",
    "age_id = fluid.create_lod_tensor([[0]], [[1]], place)\n",
    "job_id = fluid.create_lod_tensor([[10]], [[1]], place)\n",
    "movie_id = fluid.create_lod_tensor([[783]], [[1]], place) # Hunchback of Notre Dame\n",
    "category_id = fluid.create_lod_tensor([[10, 8, 9]], [[3]], place) # Animation, Children's, Musical\n",
    "movie_title = fluid.create_lod_tensor([[1069, 4140, 2923, 710, 988]], [[5]], place) # 'hunchback','of','notre','dame','the'\n",
    "print(user_id,gender_id,age_id,job_id,movie_id,category_id,movie_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inferencer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-1c0bd64b0d77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m results = inferencer.infer(\n\u001b[0m\u001b[1;32m      2\u001b[0m     {\n\u001b[1;32m      3\u001b[0m         \u001b[0;34m'user_id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;34m'gender_id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgender_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m'age_id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mage_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inferencer' is not defined"
     ]
    }
   ],
   "source": [
    "results = inferencer.infer(\n",
    "    {\n",
    "        'user_id': user_id,\n",
    "        'gender_id': gender_id,\n",
    "        'age_id': age_id,\n",
    "        'job_id': job_id,\n",
    "        'movie_id': movie_id,\n",
    "        'category_id': category_id,\n",
    "        'movie_title': movie_title\n",
    "    },\n",
    "    return_numpy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
